{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Пишем код для отправки запросов, конфигурируем модели"
      ],
      "metadata": {
        "id": "HancbKvn0bEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai >> None"
      ],
      "metadata": {
        "id": "aYXDH9StCRak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "openai.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "a9-MafOI0flR",
        "outputId": "bdfa7fac-aaf4-4f5e-a268-68bf34a8c9f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.38.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import time\n",
        "\n",
        "from google.colab import userdata\n",
        "API_KEY = userdata.get('OpenAI_API_key')\n",
        "\n",
        "client = OpenAI(api_key=API_KEY)\n",
        "\n",
        "config = {'intent':{'model':\"gpt-3.5-turbo-0125\",\n",
        "                            'system_prompt':\"\"\"You are a helpful assistant. Classify the following prompt as a 'simple' or 'hard' task.\n",
        "             The task is 'hard' only if it requires the background in computer science. Return just one lower-case word 'simple' or 'hard':\"\"\",\n",
        "                    'max_tokens':5,\n",
        "                    'price_input':0.5,\n",
        "                    'price_output':1.5},\n",
        "\n",
        "                  'easy':{'model':\"gpt-3.5-turbo-0125\",\n",
        "                           'system_prompt':\"You're a helpful assistant\",\n",
        "                           'max_tokens':None,\n",
        "                           'price_input':0.5,\n",
        "                           'price_output':1.5},\n",
        "                  'hard':{'model':\"gpt-4o\",\n",
        "                           'system_prompt':\"You're a helpful assistant\",\n",
        "                           'max_tokens':None,\n",
        "                           'price_input':5,\n",
        "                           'price_output':15}}\n",
        "\n",
        "def call_model(prompt, model_type):\n",
        "    start_time = time.time()\n",
        "    response = client.chat.completions.create(\n",
        "        model=config[model_type]['model'],\n",
        "        messages=[\n",
        "            {\"role\": \"system\",\n",
        "             \"content\": config[model_type]['system_prompt']},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        max_tokens=config[model_type]['max_tokens']\n",
        "    )\n",
        "    latency = time.time() - start_time\n",
        "\n",
        "    if model_type == 'intent':\n",
        "        intent = response.choices[0].message.content\n",
        "    else:\n",
        "        intent = None\n",
        "    tokens_input = response.usage.prompt_tokens\n",
        "    tokens_output = response.usage.completion_tokens\n",
        "    price = tokens_input*config[model_type]['price_input'] + tokens_output*config[model_type]['price_output']\n",
        "    print(response.choices[0].message.content)\n",
        "    return price, latency, intent"
      ],
      "metadata": {
        "id": "Kjr18NgHB9gW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задаем тестовые вопросы, тестируем как с ними справляется классификатор"
      ],
      "metadata": {
        "id": "DG3wP0Z60Rud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EASY_QUERY = 'Who is the best actor who played spider-man?'\n",
        "HARD_QUERY = 'What is the difference between Adam and AdamW optimizers?'\n",
        "\n",
        "call_model(HARD_QUERY, 'intent')\n",
        "call_model(EASY_QUERY, 'intent')"
      ],
      "metadata": {
        "id": "zerP80D7IvpL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aefa42d6-999b-4179-c30e-fbc5447c0d37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hard\n",
            "simple\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38.0, 0.6099886894226074, 'simple')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Используем только мощную модель"
      ],
      "metadata": {
        "id": "YIWuDcOLsv9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "price_1,latency_1, _ = call_model(HARD_QUERY, 'hard')\n",
        "price_2,latency_2, _ = call_model(EASY_QUERY, 'hard')\n",
        "tot_price = price_1 + price_2\n",
        "tot_latency = latency_1 + latency_2\n",
        "print('\\n-------------------------------\\nTOTAL PRICE IS {}, LATENCY {}'.format(tot_price, tot_latency))"
      ],
      "metadata": {
        "id": "D1iYJCVfIwDO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cce4aee3-4323-405d-e56e-20fa9cd4df21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adam and AdamW are both gradient-based optimization algorithms used in training machine learning models, particularly deep learning models. Although they share similarities, there are key differences between the two. Here's a breakdown:\n",
            "\n",
            "### Adam Optimizer:\n",
            "1. **Algorithm**: Adam (Adaptive Moment Estimation) uses estimates of first and second moments of the gradients to adapt the learning rate for each parameter.\n",
            "   \n",
            "2. **Update Rule**: The update rule for Adam is:\n",
            "   \\[\n",
            "   \\theta_{t+1} = \\theta_t - \\frac{\\alpha}{\\sqrt{\\hat{v}_t} + \\epsilon} \\hat{m}_t\n",
            "   \\]\n",
            "   Where:\n",
            "   - \\(\\theta_t\\) are the parameters at step \\(t\\),\n",
            "   - \\(\\alpha\\) is the learning rate,\n",
            "   - \\(\\hat{m}_t\\) and \\(\\hat{v}_t\\) are the bias-corrected first and second moment estimates respectively,\n",
            "   - \\(\\epsilon\\) is a small constant to prevent division by zero.\n",
            "\n",
            "3. **Weight Decay**: Traditional Adam incorporates weight decay directly into the update step, which can introduce issues by coupling the weight decay rate with the learning rate and not properly decaying weights as intended.\n",
            "\n",
            "### AdamW Optimizer:\n",
            "1. **Algorithm**: AdamW (where \"W\" stands for Weight Decay) improves upon Adam by decoupling weight decay from the gradient update. This maintains the benefits of Adam while improving handling of regularization.\n",
            "\n",
            "2. **Update Rule**: The update rule for AdamW is:\n",
            "   \\[\n",
            "   \\theta_{t+1} = \\theta_t - \\alpha (\\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon} + \\lambda \\theta_t)\n",
            "   \\]\n",
            "   Where:\n",
            "   - \\(\\lambda\\) is the weight decay coefficient.\n",
            "   - The rest of the notation is consistent with Adam.\n",
            "\n",
            "   The key difference lies in the addition of \\(\\lambda \\theta_t\\), which decouples weight decay from the gradient-based term. This allows weight decay to be managed independently of the learning rate, improving regularization properties.\n",
            "\n",
            "3. **Regularization**: AdamW applies weight decay directly to the weights after the gradient-based update, ensuring that it is solely used for regularization and not impacting the adaptive learning rate mechanism of Adam.\n",
            "\n",
            "### Practical Implications:\n",
            "- **Convergence**: AdamW often exhibits better convergence properties in practice because the weight decay does not interfere with the adaptive learning rate.\n",
            "- **Generalization**: Models trained with AdamW tend to generalize better due to more effective regularization.\n",
            "\n",
            "### Summary:\n",
            "- **Adam** blends weight decay into the optimization step, which can cause inefficiencies.\n",
            "- **AdamW** decouples weight decay from the optimization step, leading to better performance and generalization by addressing the regularization more effectively.\n",
            "The question of who the best actor to play Spider-Man is largely subjective and depends on individual preferences. Three actors have notably taken on the role in major film adaptations:\n",
            "\n",
            "1. **Tobey Maguire** - He starred in Sam Raimi's \"Spider-Man\" trilogy (2002-2007). Many fans appreciate his portrayal for its earnestness and the emotional depth he brought to Peter Parker's character.\n",
            "\n",
            "2. **Andrew Garfield** - He played Spider-Man in \"The Amazing Spider-Man\" (2012) and its 2014 sequel. Garfield's portrayal was praised for his charming and more modern take on the character, as well as his chemistry with co-star Emma Stone.\n",
            "\n",
            "3. **Tom Holland** - Holland took on the role starting in \"Captain America: Civil War\" (2016) and continued in several Marvel Cinematic Universe films, including his own standalone Spider-Man series. His portrayal is often lauded for capturing the youthful exuberance and nerdy charm of Peter Parker, aligning well with the character's comic book origins.\n",
            "\n",
            "Each actor brings a unique interpretation to the role, and preferences can vary based on which attributes of Spider-Man/Peter Parker fans most connect with.\n",
            "\n",
            "-------------------------------\n",
            "TOTAL PRICE IS 12890, LATENCY 9.93134617805481\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Используем мульти-модельность"
      ],
      "metadata": {
        "id": "r0uU7uevwY7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def router(QUERY):\n",
        "    price_intent,latency_intent, intent = call_model(QUERY, 'intent')\n",
        "    if intent.strip().lower() == 'hard':\n",
        "        price_answer, latency_answer, _ = call_model(QUERY, 'hard')\n",
        "    else:\n",
        "        price_answer, latency_answer, _ = call_model(QUERY, 'easy')\n",
        "\n",
        "    total_price = price_intent + price_answer\n",
        "    total_latency = latency_intent + latency_answer\n",
        "    return total_price, total_latency"
      ],
      "metadata": {
        "id": "sYKCKH3ptXrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "price_1,latency_1 = router(HARD_QUERY)\n",
        "price_2,latency_2 = router(EASY_QUERY)\n",
        "tot_price = price_1 + price_2\n",
        "tot_latency = latency_1 + latency_2\n",
        "print('\\n-------------------------------\\nTOTAL PRICE IS {}, LATENCY {}'.format(tot_price, tot_latency))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqBhw78wwLtN",
        "outputId": "065237af-5bb9-4c0d-da13-9edbd77be1bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hard\n",
            "Adam and AdamW are both optimization algorithms widely used in training deep learning models, but they have some key differences, primarily revolving around how they handle weight decay (regularization).\n",
            "\n",
            "### Adam Optimizer\n",
            "Adam (short for Adaptive Moment Estimation) is an optimization algorithm that combines the ideas of Momentum and RMSprop. It adapts the learning rate for each parameter based on the first and second moments of the gradients.\n",
            "\n",
            "Key features:\n",
            "1. **Adaptive Learning Rates:** It computes adaptive learning rates for each parameter.\n",
            "2. **Momentum:** Uses moving averages of the gradients (first moment) and the squared gradients (second moment).\n",
            "3. **Bias Correction:** Includes bias correction terms to account for the initialization of the moving averages.\n",
            "\n",
            "The update rule for Adam is:\n",
            "\\[ \\theta_{t+1} = \\theta_t - \\eta \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon} \\]\n",
            "where \\(\\eta\\) is the learning rate, \\(\\hat{m}_t\\) is the bias-corrected first moment estimate, and \\(\\hat{v}_t\\) is the bias-corrected second moment estimate.\n",
            "\n",
            "### AdamW Optimizer\n",
            "AdamW is a variant of Adam introduced in the paper \"Decoupled Weight Decay Regularization\" (2017) by Ilya Loshchilov and Frank Hutter. The primary modification is the way weight decay is handled. In Adam, weight decay is typically implemented by adding a penalty proportional to the L2 norm of the weights, combined with the gradient update. This coupling can lead to some issues with optimization dynamics.\n",
            "\n",
            "Key features:\n",
            "1. **Decoupled Weight Decay:** Weight decay is decoupled from the gradient update, applied directly to the weights.\n",
            "   \n",
            "The update rule for AdamW is:\n",
            "\\[ \\theta_{t+1} = \\theta_t - \\eta \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon} - \\eta \\cdot \\lambda \\cdot \\theta_t \\]\n",
            "where \\(\\lambda\\) is the weight decay coefficient.\n",
            "\n",
            "### Key Differences\n",
            "1. **Weight Decay Handling:**\n",
            "   - **Adam:** Combines weight decay with the gradient update, which can influence the adaptive learning rates.\n",
            "   - **AdamW:** Decouples weight decay from the gradient updates, applying it directly to the weights, which often leads to better generalization performance.\n",
            "  \n",
            "2. **Implementation Complexity:**\n",
            "   - **Adam:** Simpler in terms of implementation since weight decay is part of the gradient update step.\n",
            "   - **AdamW:** Slightly more complex due to the decoupling, but this often leads to improved performance.\n",
            "\n",
            "3. **Generalization:**\n",
            "   - **Adam:** Sometimes performs suboptimally in terms of generalization because the weight decay is entangled with the adaptive learning rates.\n",
            "   - **AdamW:** Tends to perform better in practice for many deep learning tasks, providing better generalization because of the proper decoupling of weight decay.\n",
            "\n",
            "### Practical Implications\n",
            "Due to the decoupling of weight decay and the gradient update, many deep learning practitioners and researchers prefer using AdamW over Adam, especially for training models where regularization and generalization are crucial.\n",
            "\n",
            "In summary, while both Adam and AdamW build on the same underlying principles, AdamW's approach to weight decay often leads to better performance and has become a preferred choice in many modern deep learning setups.\n",
            "simple\n",
            "Opinions on the best actor who played Spider-Man vary among fans, but some of the most popular choices include Tom Holland, Andrew Garfield, and Tobey Maguire. Each actor brought their own unique take on the character and contributed to the success of the Spider-Man franchise in their respective films.\n",
            "\n",
            "-------------------------------\n",
            "TOTAL PRICE IS 11040.0, LATENCY 9.423088312149048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qPRDo3bn4geS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}